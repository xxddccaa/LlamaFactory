#!/usr/bin/env python3
"""
æµ‹è¯• dataset è·¯å¾„ä¸­çš„å†…è”é…ç½®è¯­æ³•
"""
import sys
import os
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', 'src'))

from llamafactory.data.parser import _parse_dataset_path_with_config, get_dataset_list

def test_parse_dataset_path_with_config():
    """æµ‹è¯•è§£æ dataset è·¯å¾„é…ç½®"""
    print("=" * 80)
    print("æµ‹è¯• _parse_dataset_path_with_config å‡½æ•°")
    print("=" * 80)
    
    test_cases = [
        # (input, expected_path, expected_config)
        (
            "/mnt/data.json",
            "/mnt/data.json",
            {}
        ),
        (
            "/mnt/data.json[media_dir=/mnt/images]",
            "/mnt/data.json",
            {"media_dir": "/mnt/images"}
        ),
        (
            "/mnt/data.json[media_dir=/mnt/images,formatting=alpaca]",
            "/mnt/data.json",
            {"media_dir": "/mnt/images", "formatting": "alpaca"}
        ),
        (
            "s3://bucket/data.json[media_dir=s3://bucket/images]",
            "s3://bucket/data.json",
            {"media_dir": "s3://bucket/images"}
        ),
        (
            "/mnt/data.json[media_dir=/mnt/images,user_tag=user,assistant_tag=assistant]",
            "/mnt/data.json",
            {"media_dir": "/mnt/images", "user_tag": "user", "assistant_tag": "assistant"}
        ),
        (
            "/mnt/data.json[mask_history_sample=true,max_human_steps=2]",
            "/mnt/data.json",
            {"mask_history_sample": True, "max_human_steps": 2}
        ),
    ]
    
    for i, (input_str, expected_path, expected_config) in enumerate(test_cases, 1):
        print(f"\næµ‹è¯•ç”¨ä¾‹ {i}:")
        print(f"  è¾“å…¥: {input_str}")
        
        path, config = _parse_dataset_path_with_config(input_str)
        
        print(f"  è§£æç»“æœ:")
        print(f"    è·¯å¾„: {path}")
        print(f"    é…ç½®: {config}")
        
        assert path == expected_path, f"è·¯å¾„ä¸åŒ¹é…: æœŸæœ› {expected_path}, å¾—åˆ° {path}"
        assert config == expected_config, f"é…ç½®ä¸åŒ¹é…: æœŸæœ› {expected_config}, å¾—åˆ° {config}"
        print(f"  âœ“ é€šè¿‡")
    
    print("\n" + "=" * 80)
    print("æ‰€æœ‰è§£ææµ‹è¯•é€šè¿‡ï¼")
    print("=" * 80)


def test_get_dataset_list_with_inline_config():
    """æµ‹è¯• get_dataset_list æ”¯æŒå†…è”é…ç½®"""
    print("\n" + "=" * 80)
    print("æµ‹è¯• get_dataset_list å†…è”é…ç½®åŠŸèƒ½")
    print("=" * 80)
    
    # æµ‹è¯•1: åŸºæœ¬çš„ media_dir é…ç½®
    print("\næµ‹è¯•1: å¸¦ media_dir çš„æ–‡ä»¶è·¯å¾„")
    dataset_names = ["/tmp/test_data.json[media_dir=/tmp/test_images]"]
    try:
        dataset_list = get_dataset_list(dataset_names, dataset_dir="data")
        assert len(dataset_list) == 1
        assert dataset_list[0].dataset_name == "/tmp/test_data.json"
        assert dataset_list[0].media_dir == "/tmp/test_images"
        assert dataset_list[0].formatting == "sharegpt"
        print(f"  âœ“ æ•°æ®é›†åç§°: {dataset_list[0].dataset_name}")
        print(f"  âœ“ media_dir: {dataset_list[0].media_dir}")
        print(f"  âœ“ formatting: {dataset_list[0].formatting}")
    except Exception as e:
        print(f"  âœ— é”™è¯¯: {e}")
        raise
    
    # æµ‹è¯•2: å¤šä¸ªé…ç½®é¡¹
    print("\næµ‹è¯•2: å¤šä¸ªé…ç½®é¡¹")
    dataset_names = ["/tmp/test.json[media_dir=/tmp/img,formatting=alpaca,user_tag=user]"]
    try:
        dataset_list = get_dataset_list(dataset_names, dataset_dir="data")
        assert len(dataset_list) == 1
        assert dataset_list[0].media_dir == "/tmp/img"
        assert dataset_list[0].formatting == "alpaca"
        assert dataset_list[0].user_tag == "user"
        print(f"  âœ“ media_dir: {dataset_list[0].media_dir}")
        print(f"  âœ“ formatting: {dataset_list[0].formatting}")
        print(f"  âœ“ user_tag: {dataset_list[0].user_tag}")
    except Exception as e:
        print(f"  âœ— é”™è¯¯: {e}")
        raise
    
    # æµ‹è¯•3: S3 è·¯å¾„
    print("\næµ‹è¯•3: S3 è·¯å¾„é…ç½®")
    dataset_names = ["s3://bucket/data.json[media_dir=s3://bucket/images]"]
    try:
        dataset_list = get_dataset_list(dataset_names, dataset_dir="data")
        assert len(dataset_list) == 1
        assert dataset_list[0].dataset_name == "s3://bucket/data.json"
        assert dataset_list[0].media_dir == "s3://bucket/images"
        print(f"  âœ“ æ•°æ®é›†åç§°: {dataset_list[0].dataset_name}")
        print(f"  âœ“ media_dir: {dataset_list[0].media_dir}")
    except Exception as e:
        print(f"  âœ— é”™è¯¯: {e}")
        raise
    
    # æµ‹è¯•4: mask_history_sample é…ç½®
    print("\næµ‹è¯•4: mask_history_sample é…ç½®")
    dataset_names = ["/tmp/test.json[mask_history_sample=true,max_human_steps=2]"]
    try:
        dataset_list = get_dataset_list(dataset_names, dataset_dir="data")
        assert len(dataset_list) == 1
        assert dataset_list[0].mask_history_sample == True
        assert dataset_list[0].max_human_steps == 2
        print(f"  âœ“ mask_history_sample: {dataset_list[0].mask_history_sample}")
        print(f"  âœ“ max_human_steps: {dataset_list[0].max_human_steps}")
    except Exception as e:
        print(f"  âœ— é”™è¯¯: {e}")
        raise
    
    # æµ‹è¯•5: éªŒè¯é”™è¯¯ï¼ˆåªè®¾ç½® mask_history_sample ä¸è®¾ç½® max_human_stepsï¼‰
    print("\næµ‹è¯•5: éªŒè¯é”™è¯¯æ£€æµ‹ï¼ˆåªè®¾ç½® mask_history_sampleï¼‰")
    dataset_names = ["/tmp/test.json[mask_history_sample=true]"]
    try:
        dataset_list = get_dataset_list(dataset_names, dataset_dir="data")
        print(f"  âœ— åº”è¯¥æŠ›å‡º ValueError")
        raise AssertionError("Expected ValueError was not raised")
    except ValueError as e:
        print(f"  âœ“ æ­£ç¡®æŠ›å‡º ValueError: {str(e)[:80]}...")
    
    print("\n" + "=" * 80)
    print("æ‰€æœ‰ get_dataset_list æµ‹è¯•é€šè¿‡ï¼")
    print("=" * 80)


if __name__ == "__main__":
    test_parse_dataset_path_with_config()
    test_get_dataset_list_with_inline_config()
    print("\n" + "=" * 80)
    print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")
    print("=" * 80)

