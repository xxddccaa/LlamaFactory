# Copyright 2025 the LlamaFactory team.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""
æµ‹è¯• mask_history_sample åŠŸèƒ½åœ¨å¤šè¿›ç¨‹ç¯å¢ƒä¸‹çš„å…¼å®¹æ€§
"""

import os
import sys
import tempfile
import json
from pathlib import Path

# Add src to path for imports
sys.path.insert(0, str(Path(__file__).parent.parent.parent / "src"))

from datasets import Dataset
from llamafactory.data.parser import DatasetAttr
from llamafactory.data.converter import align_dataset
from llamafactory.hparams import DataArguments
from transformers import Seq2SeqTrainingArguments


def test_mask_history_sample_multiprocess():
    """
    æµ‹è¯• mask_history_sample æ•°æ®å¤„ç†åœ¨å¤šè¿›ç¨‹ä¸‹ä¸ä¼šå‡ºé”™
    """
    print("\n" + "=" * 80)
    print("æµ‹è¯•: mask_history_sample å¤šè¿›ç¨‹å…¼å®¹æ€§")
    print("=" * 80)
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    test_data = [
        {
            "conversations": [
                {"from": "user", "value": "Question 1?"},
                {"from": "assistant", "value": "Answer 1."},
                {"from": "user", "value": "Question 2?"},
                {"from": "assistant", "value": "Answer 2."},
                {"from": "user", "value": "Question 3?"},
                {"from": "assistant", "value": "Answer 3."},
            ],
            "image": []
        },
        {
            "conversations": [
                {"from": "user", "value": "Hello"},
                {"from": "assistant", "value": "Hi there!"},
                {"from": "user", "value": "How are you?"},
                {"from": "assistant", "value": "I'm doing well!"},
            ],
            "image": []
        },
    ]
    
    # åˆ›å»º Dataset
    dataset = Dataset.from_list(test_data)
    print(f"åŸå§‹æ•°æ®é›†å¤§å°: {len(dataset)}")
    
    # åˆ›å»º DatasetAttr
    dataset_attr = DatasetAttr(
        load_from="file",
        dataset_name="test_dataset",
        formatting="sharegpt",
        messages="conversations",
        images="image",
        role_tag="from",
        content_tag="value",
        user_tag="user",
        assistant_tag="assistant",
        mask_history_sample=True,
        max_human_steps=2
    )
    
    # åˆ›å»º DataArguments
    data_args = DataArguments(
        preprocessing_num_workers=2,  # æµ‹è¯•å¤šè¿›ç¨‹
        overwrite_cache=True,
    )
    
    # åˆ›å»º TrainingArguments
    with tempfile.TemporaryDirectory() as temp_dir:
        training_args = Seq2SeqTrainingArguments(
            output_dir=temp_dir,
        )
        
        # æ‰§è¡Œæ•°æ®å¯¹é½ï¼ˆä¼šè§¦å‘æ‹†åˆ†ï¼‰
        print("\nå¼€å§‹æ•°æ®å¯¹é½å’Œæ‹†åˆ†...")
        aligned_dataset = align_dataset(dataset, dataset_attr, data_args, training_args)
        
        print(f"æ‹†åˆ†åæ•°æ®é›†å¤§å°: {len(aligned_dataset)}")
        print(f"æ‹†åˆ†æ¯”ä¾‹: {len(aligned_dataset) / len(dataset):.2f}x")
        
        # éªŒè¯å­—æ®µå­˜åœ¨
        first_sample = aligned_dataset[0]
        print("\nç¬¬ä¸€ä¸ªæ ·æœ¬çš„å­—æ®µ:")
        for key in first_sample.keys():
            value = first_sample[key]
            if isinstance(value, list):
                print(f"  {key}: list[{len(value)}]")
            else:
                print(f"  {key}: {type(value).__name__}")
        
        # éªŒè¯ _mask_history_sample å­—æ®µ
        assert "_mask_history_sample" in first_sample, "ç¼ºå°‘ _mask_history_sample å­—æ®µ"
        assert first_sample["_mask_history_sample"] == True, "_mask_history_sample åº”è¯¥ä¸º True"
        
        # éªŒè¯æ‹†åˆ†é€»è¾‘
        # ç¬¬ä¸€ä¸ªæ ·æœ¬æœ‰ 3 ä¸ª assistant å›å¤ï¼Œåº”è¯¥æ‹†åˆ†ä¸º 3 ä¸ªæ ·æœ¬
        # ç¬¬äºŒä¸ªæ ·æœ¬æœ‰ 2 ä¸ª assistant å›å¤ï¼Œåº”è¯¥æ‹†åˆ†ä¸º 2 ä¸ªæ ·æœ¬
        # æ€»å…±åº”è¯¥æ˜¯ 3 + 2 = 5 ä¸ªæ ·æœ¬
        expected_samples = 3 + 2
        assert len(aligned_dataset) == expected_samples, f"æœŸæœ› {expected_samples} ä¸ªæ ·æœ¬ï¼Œå®é™… {len(aligned_dataset)}"
        
        # éªŒè¯ prompt çš„æœ€å¤§ human æ•°é‡
        max_human_count = 0
        for i in range(len(aligned_dataset)):
            sample = aligned_dataset[i]
            prompt = sample["_prompt"]
            human_count = sum(1 for msg in prompt if msg["role"] == "user")
            max_human_count = max(max_human_count, human_count)
            
            # æ¯ä¸ªæ ·æœ¬çš„ response åº”è¯¥åªæœ‰ä¸€ä¸ª
            assert len(sample["_response"]) == 1, f"æ ·æœ¬ {i} çš„ response æ•°é‡ä¸ä¸º 1"
            assert sample["_response"][0]["role"] == "assistant", f"æ ·æœ¬ {i} çš„ response è§’è‰²ä¸æ˜¯ assistant"
        
        # max_human_steps=2ï¼Œæ‰€ä»¥ prompt ä¸­æœ€å¤šåº”è¯¥æœ‰ 2 ä¸ª user æ¶ˆæ¯
        assert max_human_count <= 2, f"å‘ç° prompt ä¸­æœ‰ {max_human_count} ä¸ª user æ¶ˆæ¯ï¼Œè¶…è¿‡ max_human_steps=2"
        
        print("\nâœ… æ‰€æœ‰éªŒè¯é€šè¿‡!")
        print("=" * 80)


def test_mask_history_sample_with_images():
    """
    æµ‹è¯• mask_history_sample æ•°æ®å¤„ç†å¯¹å›¾åƒçš„å¤„ç†
    """
    print("\n" + "=" * 80)
    print("æµ‹è¯•: mask_history_sample å›¾åƒå¤„ç†")
    print("=" * 80)
    
    # åˆ›å»ºå¸¦å›¾åƒçš„æµ‹è¯•æ•°æ®
    test_data = [
        {
            "conversations": [
                {"from": "user", "value": "Image: <image>. What's this?"},
                {"from": "assistant", "value": "It's a cat."},
                {"from": "user", "value": "Image: <image>. And this?"},
                {"from": "assistant", "value": "It's a dog."},
            ],
            "image": ["image1.jpg", "image2.jpg"]
        },
    ]
    
    # åˆ›å»º Dataset
    dataset = Dataset.from_list(test_data)
    print(f"åŸå§‹æ•°æ®é›†å¤§å°: {len(dataset)}")
    print(f"å›¾åƒæ•°é‡: {len(test_data[0]['image'])}")
    
    # åˆ›å»º DatasetAttr
    dataset_attr = DatasetAttr(
        load_from="file",
        dataset_name="test_dataset",
        formatting="sharegpt",
        messages="conversations",
        images="image",
        role_tag="from",
        content_tag="value",
        user_tag="user",
        assistant_tag="assistant",
        mask_history_sample=True,
        max_human_steps=2
    )
    
    # åˆ›å»º DataArguments
    data_args = DataArguments(
        preprocessing_num_workers=2,
        overwrite_cache=True,
    )
    
    # åˆ›å»º TrainingArguments
    with tempfile.TemporaryDirectory() as temp_dir:
        training_args = Seq2SeqTrainingArguments(
            output_dir=temp_dir,
        )
        
        # æ‰§è¡Œæ•°æ®å¯¹é½
        print("\nå¼€å§‹æ•°æ®å¯¹é½å’Œæ‹†åˆ†...")
        aligned_dataset = align_dataset(dataset, dataset_attr, data_args, training_args)
        
        print(f"æ‹†åˆ†åæ•°æ®é›†å¤§å°: {len(aligned_dataset)}")
        
        # éªŒè¯å›¾åƒåˆ†é…
        for i in range(len(aligned_dataset)):
            sample = aligned_dataset[i]
            images = sample["_images"]
            
            # ç»Ÿè®¡ prompt å’Œ response ä¸­çš„ <image> token æ•°é‡
            image_token_count = 0
            for msg in sample["_prompt"] + sample["_response"]:
                content = msg.get("content", "")
                image_token_count += content.count("<image>")
            
            print(f"\næ ·æœ¬ {i}:")
            print(f"  å›¾åƒæ•°é‡: {len(images)}")
            print(f"  <image> token æ•°é‡: {image_token_count}")
            
            # å›¾åƒæ•°é‡åº”è¯¥åŒ¹é… token æ•°é‡ï¼ˆæˆ–è€…ä¸º 0ï¼‰
            if image_token_count > 0:
                assert len(images) == image_token_count or len(images) == 0, \
                    f"æ ·æœ¬ {i}: å›¾åƒæ•°é‡ ({len(images)}) ä¸ token æ•°é‡ ({image_token_count}) ä¸åŒ¹é…"
        
        print("\nâœ… å›¾åƒå¤„ç†éªŒè¯é€šè¿‡!")
        print("=" * 80)


def test_single_vs_multiprocess_consistency():
    """
    æµ‹è¯•å•è¿›ç¨‹å’Œå¤šè¿›ç¨‹çš„ç»“æœä¸€è‡´æ€§ï¼ˆåœ¨ tokenization ä¹‹å‰çš„é˜¶æ®µï¼‰
    """
    print("\n" + "=" * 80)
    print("æµ‹è¯•: å•è¿›ç¨‹ vs å¤šè¿›ç¨‹ä¸€è‡´æ€§")
    print("=" * 80)
    
    # åˆ›å»ºæµ‹è¯•æ•°æ® - æ¯ä¸ªæ ·æœ¬æœ‰ 5 è½®å¯¹è¯
    test_data = []
    for _ in range(10):  # 10 ä¸ªæ ·æœ¬
        conversations = []
        for i in range(1, 6):  # 5 turns
            conversations.append({"from": "user", "value": f"Question {i}?"})
            conversations.append({"from": "assistant", "value": f"Answer {i}."})
        test_data.append({
            "conversations": conversations,
            "image": []
        })
    
    dataset = Dataset.from_list(test_data)
    print(f"æµ‹è¯•æ•°æ®é›†å¤§å°: {len(dataset)}")
    
    # åˆ›å»º DatasetAttr
    dataset_attr = DatasetAttr(
        load_from="file",
        dataset_name="test_dataset",
        formatting="sharegpt",
        messages="conversations",
        images="image",
        role_tag="from",
        content_tag="value",
        user_tag="user",
        assistant_tag="assistant",
        mask_history_sample=True,
        max_human_steps=2
    )
    
    with tempfile.TemporaryDirectory() as temp_dir:
        training_args = Seq2SeqTrainingArguments(
            output_dir=temp_dir,
        )
        
        # æµ‹è¯•å•è¿›ç¨‹
        print("\nä½¿ç”¨å•è¿›ç¨‹å¤„ç†...")
        data_args_single = DataArguments(
            preprocessing_num_workers=1,
            overwrite_cache=True,
        )
        aligned_single = align_dataset(dataset, dataset_attr, data_args_single, training_args)
        print(f"å•è¿›ç¨‹ç»“æœ: {len(aligned_single)} ä¸ªæ ·æœ¬")
        
        # æµ‹è¯•å¤šè¿›ç¨‹
        print("\nä½¿ç”¨å¤šè¿›ç¨‹å¤„ç†...")
        data_args_multi = DataArguments(
            preprocessing_num_workers=4,
            overwrite_cache=True,
        )
        aligned_multi = align_dataset(dataset, dataset_attr, data_args_multi, training_args)
        print(f"å¤šè¿›ç¨‹ç»“æœ: {len(aligned_multi)} ä¸ªæ ·æœ¬")
        
        # éªŒè¯æ•°é‡ä¸€è‡´
        assert len(aligned_single) == len(aligned_multi), \
            f"å•è¿›ç¨‹ ({len(aligned_single)}) å’Œå¤šè¿›ç¨‹ ({len(aligned_multi)}) çš„æ ·æœ¬æ•°é‡ä¸ä¸€è‡´"
        
        # éªŒè¯å­—æ®µä¸€è‡´æ€§
        for i in range(len(aligned_single)):
            sample_single = aligned_single[i]
            sample_multi = aligned_multi[i]
            
            # æ£€æŸ¥å…³é”®å­—æ®µ
            assert len(sample_single["_prompt"]) == len(sample_multi["_prompt"]), \
                f"æ ·æœ¬ {i}: prompt é•¿åº¦ä¸ä¸€è‡´"
            assert len(sample_single["_response"]) == len(sample_multi["_response"]), \
                f"æ ·æœ¬ {i}: response é•¿åº¦ä¸ä¸€è‡´"
            assert sample_single["_mask_history_sample"] == sample_multi["_mask_history_sample"], \
                f"æ ·æœ¬ {i}: _mask_history_sample ä¸ä¸€è‡´"
        
        print("\nâœ… å•è¿›ç¨‹å’Œå¤šè¿›ç¨‹ç»“æœä¸€è‡´!")
        print("=" * 80)


if __name__ == "__main__":
    print("\n" + "=" * 80)
    print("Mask History Sample å¤šè¿›ç¨‹å…¼å®¹æ€§æµ‹è¯•å¥—ä»¶")
    print("=" * 80)
    
    try:
        # è¿è¡Œæµ‹è¯•
        test_mask_history_sample_multiprocess()
        test_mask_history_sample_with_images()
        test_single_vs_multiprocess_consistency()
        
        print("\n" + "=" * 80)
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡!")
        print("=" * 80)
        
    except Exception as e:
        print("\n" + "=" * 80)
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        print("=" * 80)
        import traceback
        traceback.print_exc()
        sys.exit(1)
